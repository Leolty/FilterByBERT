{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [SEP] The only thing needed is swype to make it complete :) 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_reader import read_combine_data\n",
    "\n",
    "app_name = \"swiftkey\"\n",
    "training_data_info = \"datasets/\" + app_name + \"/trainL/info.txt\"\n",
    "training_data_noninfo = \"datasets/\" + app_name + \"/trainL/non-info.txt\"\n",
    "# read data\n",
    "training_data1 = read_combine_data([training_data_info])\n",
    "training_data0 = read_combine_data([training_data_noninfo])\n",
    "\n",
    "trainY = np.ones(training_data1.shape[0], dtype=int)\n",
    "trainY = np.append(trainY, np.zeros(training_data0.shape[0], dtype=int))\n",
    "trainX = np.append(training_data1, training_data0, axis=0)\n",
    "\n",
    "print(trainX[0], trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  4 [SEP] The only thing needed is swype to make it complete :)\n",
      "Token IDs: [101, 1018, 102, 1996, 2069, 2518, 2734, 2003, 25430, 18863, 2000, 2191, 2009, 3143, 1024, 1007, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in trainX:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        # This function also supports truncation and conversion\n",
    "        # to pytorch tensors, but we need to do padding, so we\n",
    "        # can't use these features :( .\n",
    "        #max_length = 128,          # Truncate all sentences.\n",
    "        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', trainX[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  45\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 43...\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "trainY = torch.Tensor(trainY).long()\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, trainY, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, trainY,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1019,  102, 2292, 1005, 1055, 2156, 2129, 2009, 3248, 2041, 2058,\n",
      "        2051,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0], dtype=torch.int32) tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_9448\\1055863454.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_9448\\1055863454.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_labels = torch.tensor(validation_labels)\n"
     ]
    }
   ],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "import torch\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "print(train_inputs[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(\n",
    "    validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=2,  # The number of output labels--2 for binary classification.\n",
    "    # You can increase this for multi-class tasks.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in list(model.named_parameters())[:-36]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 20\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:03:41\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:02:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epcoh took: 0:03:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.77\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:02:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.79\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:02:42\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:02:41\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:02:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:02:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:02:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:02:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:03:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:02:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:02:50\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:02:59\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the\n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [SEP] And I want swift key to save the words I type 5 [SEP] youve been great to me\n"
     ]
    }
   ],
   "source": [
    "test_data_info = \"datasets/\" + app_name + \"/test/info.txt\"\n",
    "test_data_noninfo = \"datasets/\" + app_name + \"/test/non-info.txt\"\n",
    "# read data\n",
    "test_data1 = read_combine_data([test_data_info])\n",
    "test_data0 = read_combine_data([test_data_noninfo])\n",
    "\n",
    "testY = np.ones(test_data1.shape[0], dtype=int)\n",
    "testY = np.append(testY, np.zeros(test_data0.shape[0], dtype=int))\n",
    "testX = np.append(test_data1, test_data0, axis=0)\n",
    "\n",
    "print(test_data1[0], test_data0[613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_9448\\1457410383.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prediction_labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = testX\n",
    "labels = torch.Tensor(testY).long()\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,007 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(\n",
    "    len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s, l_s = [],[]\n",
    "\n",
    "for b in predictions:\n",
    "    for t in b:\n",
    "        p_s.append(np.argmax(t))\n",
    "\n",
    "for b in true_labels:\n",
    "    for t in b:\n",
    "        l_s.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7724498692240628 0.8699551569506726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "res_f1 = f1_score(p_s, l_s)\n",
    "res_acc = accuracy_score(p_s, l_s)\n",
    "\n",
    "print(res_f1, res_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178729c8f5e9eedf2bae7ea816478a89001acb4e6c66f13ce64ddbee9dd2f878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
