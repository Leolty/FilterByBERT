{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [SEP] The only thing needed is swype to make it complete :) 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_reader import read_combine_data\n",
    "\n",
    "app_name = \"swiftkey\"\n",
    "training_data_info = \"datasets/\" + app_name + \"/trainL/info.txt\"\n",
    "training_data_noninfo = \"datasets/\" + app_name + \"/trainL/non-info.txt\"\n",
    "# read data\n",
    "training_data1 = read_combine_data([training_data_info])\n",
    "training_data0 = read_combine_data([training_data_noninfo])\n",
    "\n",
    "trainY = np.ones(training_data1.shape[0], dtype=int)\n",
    "trainY = np.append(trainY, np.zeros(training_data0.shape[0], dtype=int))\n",
    "trainX = np.append(training_data1, training_data0, axis=0)\n",
    "\n",
    "print(trainX[0], trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  4 [SEP] The only thing needed is swype to make it complete :)\n",
      "Token IDs: [101, 1018, 102, 1996, 2069, 2518, 2734, 2003, 25430, 18863, 2000, 2191, 2009, 3143, 1024, 1007, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in trainX:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        # This function also supports truncation and conversion\n",
    "        # to pytorch tensors, but we need to do padding, so we\n",
    "        # can't use these features :( .\n",
    "        #max_length = 128,          # Truncate all sentences.\n",
    "        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', trainX[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  45\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 43...\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "trainY = torch.Tensor(trainY).long()\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, trainY, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, trainY,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1019,  102, 2292, 1005, 1055, 2156, 2129, 2009, 3248, 2041, 2058,\n",
      "        2051,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0], dtype=torch.int32) tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1055863454.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1055863454.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_labels = torch.tensor(validation_labels)\n"
     ]
    }
   ],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "import torch\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "print(train_inputs[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(\n",
    "    validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=2,  # The number of output labels--2 for binary classification.\n",
    "    # You can increase this for multi-class tasks.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(\n",
    "    len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 30\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:08:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:00:19\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:06:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:06:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:06:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:06:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:06:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:06:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:18\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:19\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:14\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:18\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:22\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:07:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:05:50\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:22\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:05:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:06:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:05:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:05:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:05:42\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the\n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAGXCAYAAAD25DXQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABSrklEQVR4nO3deVyVZf7/8fc5rMomIoK4sJkoKO4Lo+aWC9pitDilk5Vmme1ZxtSvmfrWTGoOacu0jY1rluVY455WVm6lZTkqWoCCioqgsqhs5/z+QMgjmyBwH+D1fAwTXPd9X+dzuDzwPhfXfd8mq9VqFQAAAIA6ZTa6AAAAAKAxIogDAAAABiCIAwAAAAYgiAMAAAAGIIgDAAAABiCIAwAAAAYgiANALXrmmWcUFhZW6cczzzxz1Y+1YsUKhYWFaceOHVU6bseOHQoLC9OKFSuuuoYrdeTIEYWFhen111+vs8cEAHvjaHQBANCQjRs3TlFRUSVf79q1Sx999JHGjRunnj17lrS3a9fuqh+rd+/emjVrlkJDQ6t0XGhoqGbNmqUePXpcdQ0AgCtHEAeAWtS9e3d179695OvCwkJ99NFH6tatm2666aYafay2bduqbdu2VT6uRYsWNV4LAKByLE0BAAAADEAQBwA78frrr6tLly764osv1L9/f3Xv3l3Lly+XJO3du1cPP/yw/vCHPygiIkJRUVF68skndfz48ZLjL18jXvx1fHy8nnzySfXu3Vvdu3fXgw8+qCNHjpQcd/ka8eKvt2zZohdeeEFRUVHq2rWrJk6cqPj4eJua8/Pz9dprr2nw4MHq2rWrJkyYoPj4eIWHh1dr/ffy5ct10003qUuXLurXr5+efPJJm1ol6cCBA5o0aZL69eunyMhI3Xzzzfrkk09s9jl27JgefvhhDRgwQF26dNHo0aP13nvvyWKxVLkmAKgtLE0BADtSUFCg559/Xvfcc4/y8vLUs2dPHThwQHfeeacCAwM1ZcoUNWnSRD/++KM+++wzHT58uFQIvdzUqVMVGhqqxx9/XCkpKVqwYIFOnjxZ6XHPPfecWrZsqQcffFBnz57V+++/r/vuu09fffWVHB2Lfn1Mnz5d69at080336wuXbroq6++0l133VWtwDtz5kzNnz9fUVFRevrpp3Xy5EktXrxYW7du1fLly9WmTRtlZGRo0qRJ8vb21tSpU+Xi4qLVq1fr2WeflYuLi2644Qbl5+dr8uTJunDhgu6++255enpq8+bNevXVV1VYWKgHHnigyrUBQG0giAOAHbFYLLrnnns0ZcqUkra//OUvMplMWrhwoZo1ayap6CTQ/Px8rV69WmfOnClpL0vnzp1tZqfPnTunZcuW6dChQwoKCir3OB8fHy1dulQODg6SJGdnZ82ZM0c7duxQ//79tXPnTq1bt04PPPCAHn/8cUnSnXfeqYcfflhffPFFlZ73b7/9pg8++EDDhw/X66+/LpPJJEm67rrrNG7cOM2ePVtz587V9u3blZaWpn/+85/q0qWLJCkmJkZ//OMfdfDgQUnS/v37lZCQoLlz52rUqFGSpNtuu02TJ09WUlJSleoCgNrE0hQAsDO9e/e2+fqvf/2rvvzyS5uwnZ2dLRcXF0lFwboi0dHRNl936tRJknTq1KkKjxsxYkRJCL/0uLS0NEkqCdv33HNPyT4mk0n33Xdfhf2W5auvvpLVatWUKVNKQrgkde3aVf3799fmzZtVUFAgf39/SdKcOXO0c+dOFRYWytnZWStWrNCTTz4pSWrZsqVMJpPeeecdffvtt8rLy5PJZNK//vUvzZw5s8q1AUBtYUYcAOyMj4+Pzdcmk0mnT5/WO++8owMHDig5OVnHjh2T1WqVpEqXgXh7e9t87ezsLKnoCi4Vad68eZnHFT/e4cOH1axZs1Kz8SEhIRX2W5bideDBwcGltoWGhuq7777T6dOn1aNHD911111atGiRtm3bpmbNmmnAgAG64YYbNHjwYEmSv7+/nnrqKf3jH//Q5MmT1bRpU0VFRWn06NGKjo62eXMBAEZiRhwA7IzZbPujec2aNbrhhhu0fv16+fv7a8KECVq4cKHuv//+avVX3Toul5+fLycnp1LtxTP1VVH8pqIsxcG/+LGeffZZbdiwQdOnT1eHDh20fv163X///Xr++edLjpk0aZK+/PJL/b//9//Uq1cvbdmyRU8++eQVf88AoC4QxAHAzs2ZM0eBgYFas2aNXnnlFd17773q06ePTp8+bWhdbdu2VXp6urKzs23aDx06VOW+2rRpI0lKTEwstS0pKUlNmzaVl5eXTp06pW3btqldu3a67777tGjRIn377bfq2bOnPv74Y2VlZenMmTPavn27vL29NWHCBL333nvatm2bRo4cqW+//VYHDhyo1vMFgJpGEAcAO3fmzBkFBASoadOmJW2pqanasGGDpMqXmNSW4cOHy2KxaOnSpTbtS5YsqXJfQ4YMkSS99957NrPje/fu1datWzVo0CCZTCatWLFCd999t/bs2VOyj7e3twIDA2UymWQ2m7VlyxZNnDhRX375Zck+TZs2VYcOHSSJpSkA7AZrxAHAzl177bVas2aNnn/+eXXp0kVHjhzRxx9/rPPnz0uScnJyDKmrf//+GjJkiObMmaOkpCR16dJFW7du1TfffCNJNiddVuaaa67Rn/70Jy1atEj33HOPrrvuOqWlpWnRokXy9PQsORFz7Nix+uCDD/TAAw/ojjvukJ+fn/73v/9p5cqVuvnmm+Xm5qYhQ4YoODhYzz77rPbu3at27dopMTFRS5YsUVRUlNq3b18r3w8AqCqCOADYub/+9a9q2rSpvvzyS3322Wfy9/fX2LFjNXz4cN1xxx3avn27wsPDDaktLi5OcXFxWr16tVatWqXu3bsrLi5ODz74YMnJnVfq2WefVXBwsJYtW6ZXXnlFXl5eGj58uB555BG1bt1aUtEVURYuXKh58+Zp2bJlOnPmjFq3bq2HHnqo5GotTZs21fz58zVv3jz997//1alTp+Tr66s777xTDz30UI1/DwCgukzWis6QAQCgHFlZWXJ2di51cub//vc/3XLLLXr55Zd16623GlQdANg/1ogDAKplw4YN6tatm3788Ueb9tWrV0uSIiMjjSgLAOoNZsQBANWSkZGhUaNGqUmTJho/fryaNWum3bt3a8WKFbrhhhs0e/Zso0sEALtGEAcAVFtCQoJef/117dy5U5mZmWrdurVuvvlmTZo0iauTAEAlCOIAAACAAVgjDgAAABiAIA4AAAAYoFFfR/z06RxZLHW7MsfHx13p6dmV7wjDMEb2jzGyf4yR/WOM7B9jZP8qGyOz2SRvb7dytzfqIG6xWOs8iBc/LuwbY2T/GCP7xxjZP8bI/jFG9u9qxoilKQAAAIABCOIAAACAAQjiAAAAgAEI4gAAAIABCOIAAACAAQjiAAAAgAEI4gAAAIABCOIAAACAAQjiAAAAgAEa9Z0169K2vce1YnOCMjJz1dzTRTGDQhUV4W90WQAAADAIQbwObNt7XAvWxiuvwCJJSs/M1YK18ZJEGAcAAGikWJpSB1ZsTigJ4cXyCixasTnBoIoAAABgNIJ4HUjPzK1SOwAAABo+gngd8PF0qVI7AAAAGj6CeB2IGRQqZ0fbb7Wzo1kxg0INqggAAABG42TNOlB8QuanF6+a4ursoD+NDONETQAAgEaMIF5HoiL8FRXhr9nLdiu/oJAQDgAA0MgZvjRl1apVGjNmjCIjIxUdHa2VK1dWuL/FYtE///lPDRs2TJGRkbrhhhu0evXquim2BoQFeuvw8SwVFFoq3xkAAAANlqFBfM2aNZo+fboGDBigN998U3369NGMGTO0bt26co/529/+prfeeksTJkzQO++8o65du+rJJ5/U5s2b67Dy6gsL9FZ+gUUpJ7ONLgUAAAAGMnRpSlxcnKKjoxUbGytJGjhwoM6ePau5c+dq1KhRpfZPTk7WkiVL9OKLL+q2226TJEVFRenQoUP69ttvNWjQoDqtvzrC2jWXJCUey1RwK0+DqwEAAIBRDJsRT0lJUXJyskaMGGHTPnLkSCUmJiolJaXUMRs3bpSrq6vGjh1r07548WI999xztVlujWnRzFVe7s5KOHbW6FIAAABgIMOCeGJioiQpODjYpj0wMFCSlJSUVOqYAwcOKDg4WFu3btWNN96o8PBwjRgxQmvWrKn9gmuIyWRSaICXEo9lGl0KAAAADGRYEM/KypIkubu727S7ublJkrKzS6+hzsjIUGpqqv785z9rwoQJev/99xUREaHHH39c27dvr/2ia0hogKdOnj6vrHN5RpcCAAAAgxi2RtxqtVa43Wwu/R4hPz9fGRkZevvttzVkyBBJUr9+/ZSYmKg33nhD/fr1q1INPj7ule9UC3qE+2v51wlKz8lXSKCPITWgYr6+HkaXgEowRvaPMbJ/jJH9Y4zs39WMkWFB3MOjqOicnByb9uKZ8OLtl3Jzc5ODg4P69+9f0mY2m/WHP/xBn3zySZVrSE/PlsVS8RuCmubr66Fmro4ym0z6cf8JBfm61enjo3K+vh5KS8syugxUgDGyf4yR/WOM7B9jZP8qGyOz2VThxK9hS1OK14YnJyfbtB8+fNhm+6UCAwNlsVhUUFBg056fny+TyVRLldY8F2cHtWnppkRO2AQAAGi0DAvigYGBatOmTalrhm/YsEFBQUEKCAgodczAgQNltVq1du3akraCggJ9++236tmzZ63XXJOKT9is6xl5AAAA2AdDryM+bdo0xcbGysvLS4MHD9amTZu0du1axcXFSSo6OTM5OVnt27eXu7u7oqKiNGjQIL300ks6d+6cgoKCtHTpUh09elRz5swx8qlUWUiAp7766ahS03PU2teYteoAAAAwjqFBPCYmRnl5eZo/f76WL1+utm3baubMmRo9erQk6euvv1ZsbKwWLlyovn37SpLmzZunuXPn6t1339XZs2cVHh6u+fPnq3PnzkY+lSoLbe0lSUo4lkkQBwAAaIRM1souX9KAGXWyZlpalqxWqx6Z+616hvnq7uhOdVoDKsbJMfaPMbJ/jJH9Y4zsH2Nk/+rtyZqNnclkUnCAJzf2AQAAaKQI4gYKDfDS0bQcnc8tqHxnAAAANCgEcQOFBnjKKulQKrPiAAAAjQ1B3EDBAZ6Sik7YBAAAQONCEDeQm6uTWvk0ZZ04AABAI0QQN1hIgKcSjp1VI754DQAAQKNEEDdYaICXss7lK+3sBaNLAQAAQB0iiBss5OI68cSjZw2uBAAAAHWJIG6w1r5ucnYys04cAACgkSGIG8zBbFawvydXTgEAAGhkCOJ2IKS1p5JPZCm/oNDoUgAAAFBHCOJ2IDTAS4UWqw6fyDa6FAAAANQRgrgd4IRNAACAxocgbgeaubvIx9OVdeIAAACNCEHcToS29lTiMWbEAQAAGguCuJ0ICfBSemauTmflGl0KAAAA6gBB3E6EFq8TZ3kKAABAo0AQtxPt/NzlYDYpMZXlKQAAAI0BQdxOODk6qJ2fhxKPMiMOAADQGBDE7UhogKeSjmeq0GIxuhQAAADUMoK4HQlp7am8fIuOpuUYXQoAAABqGUHcjoQGeEkS1xMHAABoBAjidqSFl6s8mzpxh00AAIBGgCBuR0wmk0ICvJgRBwAAaAQI4nYmtLWnjmecU/b5fKNLAQAAQC0iiNuZkFZFN/ZJSmVWHAAAoCEjiNuZoFaeMok7bAIAADR0BHE708TFUa193ZRwjBM2AQAAGjKCuB0KCfBS0rFMWaxWo0sBAABALSGI26HQAE/lXCjQiYxzRpcCAACAWkIQt0MhrYtu7MM6cQAAgIaLIG6HWvk0VRMXB64nDgAA0IARxO2Q2WRSSCtP7rAJAADQgBHE7VRIgJdS0rKVm1dodCkAAACoBYYH8VWrVmnMmDGKjIxUdHS0Vq5cWeH+n332mcLCwkp9vPjii3VTcB0JCfCU1SodOs7yFAAAgIbI0cgHX7NmjaZPn66JEydqwIAB2rhxo2bMmCFXV1eNGjWqzGPi4+MVGBioWbNm2bS3aNGiLkquMyEBRXfYTDyWqbB23gZXAwAAgJpmaBCPi4tTdHS0YmNjJUkDBw7U2bNnNXfu3HKD+IEDBxQREaFu3brVYaV1z6Ops1p6N+GETQAAgAbKsKUpKSkpSk5O1ogRI2zaR44cqcTERKWkpJR5XHx8vMLCwuqiRMOFBngq4ehZWbmxDwAAQINjWBBPTEyUJAUHB9u0BwYGSpKSkpJKHXPy5Emlp6dr3759GjVqlCIiIjRy5MhK15XXVyEBXjqbk6eMzFyjSwEAAEANM2xpSlZWliTJ3d3dpt3NzU2SlJ2dXeqY+Ph4SdKRI0f01FNPycXFRStXrtSMGTNUWFioW265pZarrluhrYvWiSccOysfL1eDqwEAAEBNMiyIV7bcwmwuPVnfuXNnvf322+rdu3dJgB8wYIDS09M1d+7cKgdxHx/3yneqBb6+Hle0n3dzNzk7mpV6+sIVH4Oawffb/jFG9o8xsn+Mkf1jjOzf1YyRYUHcw6Oo6JycHJv24pnw4u2Xat68uYYMGVKqfdCgQdq6dasyMjLUvHnzK64hPT1bFkvdrr/29fVQWlrWFe8f6O+h/yWkVekYXJ2qjhHqHmNk/xgj+8cY2T/GyP5VNkZms6nCiV/D1ogXrw1PTk62aT98+LDN9kv99NNPWr58ean23NxcOTo6lhne67vQAC8dPp6t/AKL0aUAAACgBhkWxAMDA9WmTRutW7fOpn3Dhg0KCgpSQEBAqWN2796t5557rmStuCRZLBatX79ePXr0kJOTU63XXddCAjxVUGhRysnSa+YBAABQfxl6HfFp06YpNjZWXl5eGjx4sDZt2qS1a9cqLi5OkpSRkaHk5GS1b99e7u7uiomJ0cKFC/XQQw/psccek5ubm5YuXaqDBw9qyZIlRj6VWvP7jX3OlnwOAACA+s/QW9zHxMTohRde0Hfffadp06bphx9+0MyZMzV69GhJ0tdff61x48Zp7969kiQvLy8tXrxYkZGR+vvf/67HHntM586d07///W917drVyKdSa5p7usrbw0WJ3NgHAACgQTFZG/HdYurDyZqS9OZ/9ij5RJZmPvCHWqoKl+LkGPvHGNk/xsj+MUb2jzGyf/X2ZE1cudAAL6WduaDMnDyjSwEAAEANIYjXA7+vE2d5CgAAQENBEK8HAv095GA2KeHYWaNLAQAAQA0hiNcDLk4OatPSnRlxAACABoQgXk+EBngqMTWzzk8uBQAAQO0giNcTIQGeys0r1LFTOUaXAgAAgBpAEK8nQgO8JEmJqSxPAQAAaAgI4vVES+8mcnN1VMJRTtgEAABoCAji9YTJZFJoay9O2AQAAGggCOL1SEiAp46dytG5CwVGlwIAAICrRBCvR0IDvGSVlHScWXEAAID6jiBejwS38pRJUiLrxAEAAOo9gng90tTVUa1auCmBdeIAAAD1HkG8ngkJ8FTisUxZrdzYBwAAoD4jiNczIQGeyj6fr5NnzhtdCgAAAK4CQbyeKbmxD8tTAAAA6jWCeD3TuoWbXJwclHiUIA4AAFCfEcTrGbPZpOBWHko4xpVTAAAA6jOCeD0U2tpLKSezlZdfaHQpAAAAqCaCeD0UEuCpQotVh09kGV0KAAAAqokgXg+FXDxhM4F14gAAAPUWQbwe8nJzVgsvVyWyThwAAKDeIojXUyEBntxhEwAAoB4jiNdToQFeOp2Vq9NZuUaXAgAAgGogiNdTIa09JYnlKQAAAPUUQbyeatfSQ44OJpanAAAA1FME8XrKydGsQD8PJR5lRhwAAKA+IojXYyEBXjp0PEsFhRajSwEAAEAVORpdAKrPYrEor8CiKbO/lo+ni2IGhSoqwt/osgAAAHAFmBGvp7btPa5vfkkt+To9M1cL1sZr297jBlYFAACAK0UQr6dWbE5QfoHtkpS8AotWbE4wqCIAAABUBUG8nkrPLPv64eW1AwAAwL4QxOspH0+XKrUDAADAvhDE66mYQaFydrQdPmdHs2IGhRpUEQAAAKqCq6bUU8VXR1mxOUHpmbkym6S7RoVx1RQAAIB6wvAZ8VWrVmnMmDGKjIxUdHS0Vq5cecXHpqamqmfPnnrrrbdqr0A7FhXhr9kP9td914fLYpVaejc1uiQAAABcIUOD+Jo1azR9+nQNGDBAb775pvr06aMZM2Zo3bp1lR5rtVr15z//WdnZ2XVQqX3r2r6FHMwm7Yw/aXQpAAAAuEKGLk2Ji4tTdHS0YmNjJUkDBw7U2bNnNXfuXI0aNarCY5cuXarExMS6KNPuNXV1VERwc+06kKZxQ9vLZDIZXRIAAAAqYdiMeEpKipKTkzVixAib9pEjRyoxMVEpKSkVHvvqq6/q//7v/2q7zHqjV1hLpWde0KHjWUaXAgAAgCtgWBAvns0ODg62aQ8MDJQkJSUllXmcxWLRM888o+joaF177bW1W2Q90u2ai8tTDrA8BQAAoD4wLIhnZRXN3Lq7u9u0u7m5SVK5a78XLFigI0eOlCxnQRH3Jk7qGOitXfFpslqtRpcDAACAShi2RryysGg2l36PkJCQoNdee03z5s2Th4fHVdfg4+Ne+U61wNf36msvy5BebfXG8p+VnW9VSGvPWnmMxqK2xgg1hzGyf4yR/WOM7B9jZP+uZowMC+LFQTonJ8emvXgm/PKgXVhYqNjYWI0aNUr9+/dXQUFByTaLxaKCggI5Olbt6aSnZ8tiqdvZY19fD6Wl1c467vatPGQySV9sP6SYa0Nq5TEag9ocI9QMxsj+MUb2jzGyf4yR/atsjMxmU4UTv4YtTSleG56cnGzTfvjwYZvtxVJTU/Xzzz9r5cqVioiIKPmQpNdff73k88bMs6mzOrbz1s74kyxPAQAAsHOGzYgHBgaqTZs2WrdunYYPH17SvmHDBgUFBSkgIMBm/5YtW+qTTz4p1c+tt96qO+64Q7fcckut11wf9Azz1eINB3XsVI5a+xqz9AYAAACVM/Q64tOmTVNsbKy8vLw0ePBgbdq0SWvXrlVcXJwkKSMjQ8nJyWrfvr3c3d3VpUuXMvtp2bJludsamx4dfLVkw0HtPJBGEAcAALBjht5ZMyYmRi+88IK+++47TZs2TT/88INmzpyp0aNHS5K+/vprjRs3Tnv37jWyzHqlmbuLrmnjpV1cxhAAAMCuGTojLkl//OMf9cc//rHMbTExMYqJianw+AMHDtRGWfVaz44t9eHGX5WanqNWPm5GlwMAAIAyGDojjtrRs4OvJGnXgTSDKwEAAEB5COINUHNPV4UGeHKXTQAAADtGEG+geoa1VPKJbJ08c97oUgAAAFAGgngD1SuseHkKs+IAAAD2iCDeQLVo1kRB/h7aGc86cQAAAHtEEG/Aeob5Kik1U6fOsjwFAADA3hDEG7BeYS0lST9y9RQAAAC7QxBvwPyaN1Xblu7aeZAgDgAAYG8I4g1crzBf/XbkrE5n5RpdCgAAAC5BEG/gehYvT2FWHAAAwK4QxBu4gBZuCmjhpp3xXMYQAADAnhDEG4FeYb46mHJGZ3PyjC4FAAAAFxHEG4FeYS1llfQTy1MAAADsBkG8EWjt6ya/5k21k7tsAgAA2A2CeCNgMpnUK8xX8YfPKOscy1MAAADsAUG8kegV1lIWq1U//XrK6FIAAAAggnij0c7PXS28XLWLu2wCAADYBYJ4I2EymdSrY0vtO5ShnAv5RpcDAADQ6BHEG5GeYb4qtFi1m+UpAAAAhqtWELdarUpJSSn5OikpSTNnztScOXOUlJRUY8WhZoW08lRzTxeWpwAAANgBx6oecPz4cU2aNEnOzs76z3/+o1OnTun2229XVlaWJGnx4sVasmSJwsPDa7xYXB2TyaSeHVrqq5+O6HxugZq4VHn4AQAAUEOqPCP+j3/8Q6mpqbrjjjskSR9//LGysrL02muvadOmTWrVqpXmzZtX44WiZvTq6KuCQqt+TmB5CgAAgJGqHMS3bNmiiRMn6vbbb5ckffnll2rVqpVGjRql1q1b6/bbb9ePP/5Y44WiZoS29pKXu7N2xbM8BQAAwEhVDuJZWVlq06aNJCk9PV179+7VwIEDS7Y3adJEBQUFNVchapTZZFLPDr76JTFdF/IYJwAAAKNUOYgHBATo4MGDkqTVq1dLkoYMGVKy/dtvvy0J6rBPvcJaKr/Aoj2JGUaXAgAA0GhV+Wy966+/Xm+99ZYOHz6sHTt2qFWrVho4cKCSk5P1t7/9TZs3b9YzzzxTG7WihnRo20weTZ2068BJ9e7Y0uhyAAAAGqUqB/GHHnpIDg4OWrVqlXr06KGnn35ajo6Oys7O1s6dO/XAAw9o4sSJtVEraojZXLQ8ZdveE8rLL5Szk4PRJQEAADQ61bp+3dSpUzV16lSbtk6dOmnbtm1ycnKqkcJQu3qGtdTXu4/pf0kZ6tHB1+hyAAAAGp1q31nz/PnzJZ+fPn1aS5cu1aeffqozZ87URF2oZWHtmsnN1VE7D5w0uhQAAIBGqcoz4pmZmXr88ceVmZmp5cuXKzs7W7fccotSU1NltVr15ptvaunSpWrbtm1t1Isa4uhgVvcOvtp14KTyCyxycqz2ezIAAABUQ5XT12uvvaYdO3aUXLLwk08+0bFjx/TUU09p4cKFMpvNeu2112q6TtSCXmEtdT63UPsOcfUUAACAulblIP7ll19qwoQJeuSRRyRJGzdulI+Pj+6991716dNH48eP19atW2u8UNS88CBvNXFheQoAAIARqhzE09PTdc0110gqurnP7t271b9//5Lt3t7eNuvHYb8cHczq1r6Ffjp4SgWFFqPLAQAAaFSqHMT9/PyUkpIiqWg2vLCwUIMHDy7Z/uOPP6pVq1Y1ViBqV6+OvjqXW6D4w6eNLgUAAKBRqfLJmkOGDNGCBQuUnZ2t1atXy8vLS0OHDtWJEyf03nvv6bPPPtODDz5YG7WiFnQObi4XZwftPJCmziE+RpcDAADQaFR5Rvypp57SmDFj9Mknn8jT01NxcXFydXXViRMntGTJEt1www2aMmXKFfe3atUqjRkzRpGRkYqOjtbKlSsr3P/kyZOaPn26oqKi1KNHDz344IM6fPhwVZ8GLnJydFC39i3048E0FVpYngIAAFBXqjwj7uzsrJdeekkvvfSSTXvHjh21efNmtWx55bdMX7NmjaZPn66JEydqwIAB2rhxo2bMmCFXV1eNGjWq1P65ubmaPHmycnNz9fzzz8vV1VVvvvmmJkyYoNWrV8vT07OqTweSenbw1Y59J3Qw+Yw6BTU3uhwAAIBGoVp31pSkM2fOaOvWrTp69KicnJzUqlUrm5M2r0RcXJyio6MVGxsrSRo4cKDOnj2ruXPnlhnEv/rqKx04cECffvqpOnfuLEm65pprNGzYMK1fv1633XZbdZ9Oo9Yl1EfOTmbtPJBGEAcAAKgj1QriS5cu1ezZs3XhwgVZrdaSdhcXFz399NMaP358pX2kpKQoOTlZTzzxhE37yJEjtXbtWqWkpJS6KdCAAQP04YcfloRwSXJycpIk5eXlVeepQJKLk4MiQ3y062Caxg/vILPZZHRJAAAADV6Vg/jGjRv14osvKjw8XJMnT1ZISIisVqsSExP1wQcf6KWXXlJAQICGDBlSYT+JiYmSpODgYJv2wMBASVJSUlKpIO7u7q4ePXpIkvLz85WQkKCZM2fK29tbw4cPr+pTwSV6dWypnQfS9NvRs+rQtpnR5QAAADR4VQ7i7733nsLDw7Vs2TI5OzuXtHfq1EkjRozQuHHj9P7771caxLOysiQVhetLubm5SZKys7MrPP7hhx/WV199JbPZrJdffrlKa9NRWpcQHzk5mrUz/iRBHAAAoA5UOYjHx8friSeesAnhxZycnHTTTTdp7ty5lfZz6ZKWspjNFV/Q5b777tPEiRP1+eefl6wxj4mJqfRxL+Xj4175TrXA19fDkMetTI+wlvrpt1N6+I89Gv3yFHsdI/yOMbJ/jJH9Y4zsH2Nk/65mjKp11ZSK7pyZk5MjBweHSvvx8PAo2f9SxTPhxdvL07NnT0lSVFSUjh49qnfeeafKQTw9PVsWS8VvCGqar6+H0tKy6vQxr1RkcHPt2HtcO345qvatvYwuxzD2PEYowhjZP8bI/jFG9o8xsn+VjZHZbKpw4rfK1xHv3bu3lixZopMnT5baduLECS1durQkJFekeG14cnKyTXvxNcEvXzsuSfv27dPq1atLtUdERJRZD6qma/sWcjCbtOsA30sAAIDaVuUZ8ccee0zjxo1TdHS0xo4dq6CgIElFJ19+/vnnKiws1KOPPlppP4GBgWrTpo3WrVtnc6Llhg0bFBQUpICAgFLHbN++XbNmzVKXLl3Url07SVJhYaG2b9+uDh06VPWp4DJNXR0V0KKpvvghReu/T5GPp4tiBoUqKsLf6NIAAAAanCoH8Q4dOmjBggV66aWXtGTJEpttnTt31nPPPadOnTpdUV/Tpk1TbGysvLy8NHjwYG3atElr165VXFycJCkjI0PJyclq37693N3dFRMTo0WLFmnq1Kl6+OGH5erqqiVLlujgwYOaP39+VZ8KLrNt73EdO3VOxat10jNztWBtvCQRxgEAAGqYyVrZWZMVSE9P19GjR2W1WtW6dWu1aNFC27dv18GDB3XXXXddUR/Lli3T/PnzlZqaqrZt22rKlCkaO3asJGnFihWKjY3VwoUL1bdvX0nS0aNH9eqrr2rHjh3KyclRZGSkHn30UfXq1asa9bNG/FJPvbVF6Zm5pdp9PF00+8Gq3aypPrPnMUIRxsj+MUb2jzGyf4yR/bvaNeJXFcTL8pe//EUff/yx9u/fX5Pd1gqCuK17X/my3G3znxlah5UYy57HCEUYI/vHGNk/xsj+MUb2r85P1kTD5ePpUqV2AAAAVB9BHCViBoXK2dH2n4Szo1kxg0INqggAAKDhqvLJmmi4ik/IXLE5QemZuTKZpD+NDONETQAAgFpAEIeNqAh/RUX468eDaXpjxR55upW+gyoAAACuXqVB/NixY1Xq8PI7ZaJ+6hLio6Yujtq+94S6hPgYXQ4AAECDU2kQHzp0qEwm0xV3aLVaq7Q/7JOTo1m9Ovpqx/6Tys0vlIuTg9ElAQAANCiVBvGxY8cSrBupvuH++ubnVP382yn16eRndDkAAAANSqVB/JVXXqmLOmCHwto2UzN3Z23fe4IgDgAAUMO4fCHKZTab1DfcT3sS05V9Pt/ocgAAABoUgjgq1C/cX4UWq3YdOGl0KQAAAA0KQRwVaufnLv/mTbV97wmjSwEAAGhQCOKokMlkUr9wPx1MOaOMzAtGlwMAANBgEMRRqb4RfrJK+n4/y1MAAABqCkEclfLzbqrgVp7avve40aUAAAA0GARxXJF+4X5KPpmto6e4cyoAAEBNIIjjivTp1FImk7RjHydtAgAA1ASCOK6Il7uLwgO9tWPfcVmtVqPLAQAAqPcI4rhifcP9lXbmghKPZRpdCgAAQL1HEMcV69HBV44OZm1neQoAAMBVI4jjijV1dVS39j76Yf8JFVosRpcDAABQrxHEUSV9w/2VeS5f+w+dNroUAACAeo0gjiqJDG2uJi6OLE8BAAC4SgRxVImTo4N6hflq18E05eUXGl0OAABAvUUQR5X1C/dTbl6hfk5IN7oUAACAeosgjioLa+ctL3dnbnkPAABwFQjiqDKz2aS+nfz0S0K6ci7kG10OAABAvUQQR7X0i/BTocWqXQfSjC4FAACgXiKIo1oC/Tzk17wpy1MAAACqiSCOajGZTOoX7qcDyWeUkXnB6HIAAADqHYI4qq1fuJ+skr7ff9LoUgAAAOodgjiqza95UwW38tAObu4DAABQZQRxXJW+4f46fCJLqek5RpcCAABQrxDEcVX6dGopk0navpdZcQAAgKogiOOqNHN3UadAb+3Yd0JWq9XocgAAAOoNw4P4qlWrNGbMGEVGRio6OlorV66scP+0tDQ999xzGjJkiLp3766YmBitXbu2bopFmfqG++nkmfNKSs0yuhQAAIB6w9HIB1+zZo2mT5+uiRMnasCAAdq4caNmzJghV1dXjRo1qtT+eXl5mjx5srKysvTII4+oZcuWWr9+vR577DEVFhbq+uuvN+BZoGeHllq0/qC27z2ukABPo8sBAACoFwwN4nFxcYqOjlZsbKwkaeDAgTp79qzmzp1bZhD/5ptvFB8fr+XLlysyMlKS1L9/fx07dkzvvfceQdwgTV0d1bW9j76PP6lxw9rLwWz4H1oAAADsnmGJKSUlRcnJyRoxYoRN+8iRI5WYmKiUlJRSx7i5uWncuHHq0qWLTXtISIiSk5NrtV5UrF+4nzJz8hR/+IzRpQAAANQLhs2IJyYmSpKCg4Nt2gMDAyVJSUlJatu2rc22qKgoRUVF2bTl5+dr8+bNuuaaa2qxWlQmMtRHTVwctX3vcUUENze6HAAAALtn2Ix4VlbRiX3u7u427W5ubpKk7OzsK+pn9uzZOnTokKZMmVKzBaJKnBwd1DPMV7sOpikvv9DocgAAAOyeYTPilV3qzlzJOmOr1arZs2drwYIFmjRpkq677roq1+Dj4175TrXA19fDkMetbaOigvXdL6k6lHZO/bsGGF3OVWmoY9SQMEb2jzGyf4yR/WOM7N/VjJFhQdzDo6jonBzbOzIWz4QXby9LXl6ennnmGa1evVqTJk3S008/Xa0a0tOzZbHU7bWvfX09lJbWMC/z5+/lIi83Z23YfkgdAurvD46GPEYNBWNk/xgj+8cY2T/GyP5VNkZms6nCiV/DlqYUrw2//CTLw4cP22y/XHZ2tu655x6tXbtWf/7zn6sdwlHzzGaT+nTy0y8Jp5RzId/ocgAAAOyaYUE8MDBQbdq00bp162zaN2zYoKCgIAUElF7aUFhYqKlTp+rnn39WXFycJk6cWFfl4gr1i/BTQaFVuw6kGV0KAACAXTP0OuLTpk1TbGysvLy8NHjwYG3atElr165VXFycJCkjI0PJyclq37693N3dtWzZMn3//fcaN26c/P39tXv37pK+TCaTunbtatAzQbEgfw/5eTfRjn0ndG09XycOAABQmwwN4jExMcrLy9P8+fO1fPlytW3bVjNnztTo0aMlSV9//bViY2O1cOFC9e3bV+vXr5ckffTRR/roo49s+nJwcNC+ffvq/DnAlslkUt9wP/13yyGdzsqVt4eL0SUBAADYJZO1ssuXNGCcrFk7jmec05/f3a5xQ9trZJ92RpdTZY1hjOo7xsj+MUb2jzGyf4yR/au3J2ui4fJv3lRB/h7avu+E0aUAAADYLYI4akW/cD8dPp6l1PScyncGAABohAjiqBW9O/nJJGkHs+IAAABlIoijVnh7uKhjoLe27ztR6V1UAQAAGiOCOGpNv3A/nTx9XoeOc6IJAADA5QjiqDU9w3zl6GDStr3HjS4FAADA7hDEUWuaujqpa2gLfb//ZJ1fJhIAAMDeEcRRq/qG+ykzJ0/7k08bXQoAAIBdIYijVkWG+qiJi4N27OXqKQAAAJcy9Bb3aPicnRzUxtdNW/ak6rs9qfLxdFHMoFBFRfgbXRoAAIChmBFHrdq297iSUrNUvEI8PTNXC9bGcwInAABo9AjiqFUrNieooND2RM28AotWbE4wqCIAAAD7QBBHrUrPzK1SOwAAQGNBEEet8vF0qVI7AABAY0EQR62KGRQqZ0fbf2Ymk3TztSEGVQQAAGAfuGoKalXx1VFWbE5Qemaumro46lxugRwdeA8IAAAaN4I4al1UhH9JIC+0WPS3Rbu0eMNBdQz0lmdTZ4OrAwAAMAbTkqhTDmaz7h3dSRfyCrRkw0GjywEAADAMQRx1rrWvu27oH6wf4k9q14GTRpcDAABgCII4DBHdt53a+blr0foDyj6fb3Q5AAAAdY4gDkM4Opg1aUy4ci4UaOlGlqgAAIDGhyAOw7Rt6a7r/xCk7XtP6Kdf04wuBwAAoE4RxGGoMVGBauPrroXrDyjnAktUAABA40EQh6GKlqh0UlZOvpZt/NXocgAAAOoMQRyGC/T30Oiodtryv+P6JSHd6HIAAADqBEEcduGGPwSrdQs3LVgXr3MXCowuBwAAoNYRxGEXnBzNundMJ53JztVHX7JEBQAANHwEcdiN4FaeGtW3nb79JVX/S2KJCgAAaNgI4rArYwcEq5VPUy1YG6/zuSxRAQAADRdBHHbFydFB947upIysXC3/OsHocgAAAGoNQRx2J7S1l0b0bquvfzqq/YcyjC4HAACgVhDEYZduHhgiP+8m+mBtvC7ksUQFAAA0PARx2CVnJwfdM7qT0s9e0KdfJxpdDgAAQI0jiMNudWjbTMN6ttGmH4/oQPJpo8sBAACoUQRx2LVbBoXKt5mrPlgTr9z8QqPLAQAAqDGGB/FVq1ZpzJgxioyMVHR0tFauXHnFx86cOVN33313rdUG47k4O+ie6E46eea8VmxmiQoAAGg4DA3ia9as0fTp0zVgwAC9+eab6tOnj2bMmKF169ZVeuyiRYs0f/78OqgSRusY6K0hPVpr484U/XrkjNHlAAAA1AhHIx88Li5O0dHRio2NlSQNHDhQZ8+e1dy5czVq1Kgyjzlx4oRmzZqlNWvWyMPDoy7LhYFuGxyqX35L1/w18Xrhnt5ydnIwuiQAAICrYtiMeEpKipKTkzVixAib9pEjRyoxMVEpKSllHhcXF6d9+/bpgw8+UKdOneqiVNgBV2dH3T26o05knNPK75KMLgcAAOCqGRbEExOL1vsGBwfbtAcGBkqSkpLKDluTJ0/W6tWr1a9fv9otEHYnIqi5BnUL0Prvk5Vw7KzR5QAAAFwVw4J4VlaWJMnd3d2m3c3NTZKUnZ1d5nHt27eX2Wz4OaYwyO1D2svbw0XzV+9XfgFXUQEAAPWXYWvErVZrhdvrImz7+LhXvlMt8PVlbfvVeHRcD/3lvW16/I0tOn+hQC28m+iu6E4a3LNtjT0GY2T/GCP7xxjZP8bI/jFG9u9qxsiwIF58omVOTo5Ne/FMeF2ciJmeni2LpeI3BDXN19dDaWlZdfqYDc2R42dlNknnLhRIktJOn9frH+9WZtYFRUX4X3X/jJH9Y4zsH2Nk/xgj+8cY2b/KxshsNlU48WvYGo/iteHJyck27YcPH7bZDlxuxeYEXf7+Ka/AohWbE4wpCAAAoBoMC+KBgYFq06ZNqWuGb9iwQUFBQQoICDCoMti79MzcKrUDAADYI0OvIz5t2jTFxsbKy8tLgwcP1qZNm7R27VrFxcVJkjIyMpScnKz27duXOqkTjZePp0uZobuZu4sB1QAAAFSPoZcfiYmJ0QsvvKDvvvtO06ZN0w8//KCZM2dq9OjRkqSvv/5a48aN0969e40sE3YmZlConB1L/9O1WCw6ncWsOAAAqB9M1souX9KAcbJm/bVt73Gt2Jyg9Mxc+Xi6qH+XVlr/Q4qaubtoxp3dr2p2nDGyf4yR/WOM7B9jZP8YI/t3tSdrGro0BaiuqAj/UldICQ9qrriPf9bsD3/S03d0lxdLVQAAgB3jzjhoMDq0babHbotUeuYFzV62W5k5eUaXBAAAUC6COBqUsHbeevy2rjp19rxmf/iTMs8RxgEAgH0iiKPBCWvnrUdv7aq0M+f16oc/KYswDgAA7BBBHA1Sp0BvPXJrpE6cPq/ZH+5W9vl8o0sCAACwQRBHgxUe1FwP39JFxzPO6dUPfyKMAwAAu0IQR4PWOdhHD9/SRcfSczRn2W7lXCCMAwAA+0AQR4PXJcRHD8V00dFT2ZqzbLfOEcYBAIAdIIijUYgMbaEHb+6ilJPZmvPRzzp3ocDokgAAQCNHEEej0a19Cz04trOST2Qp7uPdOp9LGAcAAMYhiKNR6d7BVw/c1FmHjmcp7uOfCeMAAMAwBHE0Oj3DfHX/jRFKPJap15b/rAt5hHEAAFD3COJolHp1bKn7b4pQwtFMvbb8F+XmFRpdEgAAaGQI4mi0endsqSk3huvXI2c095OflZtPGAcAAHXH0egCACP16eQni8Wq91bt0//9+wddyCvU6axcNfd0UcygUEVF+BtdIgAAaKAI4mj0+kX469eUM/pq97GStvTMXC1YGy9JhHEAAFArWJoCSPolMb1UW16BRSs2JxhQDQAAaAwI4oCKZsDLa89j7TgAAKgFBHFAko+nS7nbnv7nVq3edkjnLuTXYUUAAKChI4gDkmIGhcrZ0fbl4Oxo1vVRgWrn76FPNydq+ltb9fFXv+l0Vtmz5wAAAFXByZqAfj8hc8XmBGVklr5qSvKJLK3dkaz13ydr484U/aGzv0b1DZR/86ZGlg0AAOoxk9VqtRpdhFHS07NlsdTt0/f19VBaWladPiaqpqIxOnnmvNZ/n6zvfklVQYFFPcJ8NbpfoIJbedZxlY0bryP7xxjZP8bI/jFG9q+yMTKbTfLxcS93OzPiQBW0bNZEfxoRppv6B2vjrhR9ueuodh1IU6dAb43uF6jwIG+ZTCajywQAAPUAQRyoBk83Z8VcG6rovoHavPuYNvyQrDkf7VY7P3eN7heoXmEtZTYTyAEAQPkI4sBVaOLiqFF922lYzzbavve41u5I1tuf7VXLZoka1bedHB1M+uy7JKVn5sqHu3UCAIBLEMSBGuDkaNbArgHqH9lKPx08pTXbD2vh+gM2+3C3TgAAcCkuXwjUILPJpJ5hvnrurp7ybOpUantegUWLNxzUvkMZXJccAIBGjhlxoBaYTCZlnis7aJ/PLdCry3ZLkvy8myiolaeC/T0U1MpTgX4ecnF2qMNKAQCAUQjiQC3x8XRRembpm/94e7jo3tGdlJSaqUPHs3Qw5Yx27DshSTKZpAAfNwW18lCQv6eCW3mqbUs3OTn+Hs637T2uFZsTWHcOAEA9RxAHaknMoFAtWBuvvAJLSZuzo1m3Dg5VRHBzRQQ3L2k/m52rpONZOnQxnP+SkK4te45LkhzMJrXxdVdQKw9ZLFZt33tC+YVFfbLuHACA+osgDtSSS+/WWdnstZe7i7q1d1G39i0kSVarVRmZuTp0PFNJqVk6dDxTP+w/qXO5BaWOzSuwaMXmBII4AAD1DEEcqEVREf7VCsgmk0k+Xq7y8XJVz7CWkorC+aSZX5W5f3pmrv679ZB6XNNCAS3cuKkQAAD1AEEcqCdMJlO5684dHUz6zzeJ+s83iWrp3UQ9OviqxzW+CmntKTOhHAAAu0QQB+qR8tadT4zuqE6B3tr96yn9eDBNX/yQonU7kuXp5qxu7VuoR4cW6hTYXE6OXLEUAAB7QRAH6pHK1p0P7t5ag7u31rkLBdqTmK6ffk3T9/tP6Jufj8nF2UGRIT7q3qGFIkNaqKnr7y9/rsQCAEDdMzyIr1q1Sv/85z+VkpKi1q1b6/7779fYsWPL3T8nJ0evvvqqNmzYoHPnzqlXr1569tlnFRQUVGc1A0a6knXnTV0d1TfcT33D/ZRfYNH+w6f1069p+unXU/oh/qQczCZ1DPRWjw6+KrRY9MlXCSWz7FyJBUBDxaRD42TP425oEF+zZo2mT5+uiRMnasCAAdq4caNmzJghV1dXjRo1qsxjHn/8ce3Zs0dPP/203Nzc9MYbb+iuu+7S6tWr5eHhUcfPALB/To5mRYb6KDLUR38aaVXi0Uz9+GuafjyYpkXrD5R5TF6BRZ9e5ZVYauMHX3GfGZm5al7DfdrjD2gANWfb3uM2S/uYdGgc7H3cTVar1WrUgw8fPlydO3dWXFxcSdtjjz2mAwcOaO3ataX237lzp8aPH6/33ntP1157rSQpIyNDw4YN09SpUzVlypQqPX56erYslrp9+r6+HkpLy6rTx0TVNJYxslqtOpZ+Tv/v/R3l7uPq7CD3Jk5FH02d5NHESW5Niv7r3tS5ZJvHxe3uTZzk6GAu9YNP+n0te3V/8NWXPov7ra03IfWlT3t/s0SfjWuM8gssmvH2Vp3Jziu1rbmni159sL9d1Hl5n41pjGqqT6vVqqzz+crIvKCMzFzNX7Nf5y6UvvSvj6eLZl/FuBerLDOYzSb5+LiXu92wGfGUlBQlJyfriSeesGkfOXKk1q5dq5SUFLVt29Zm25YtW+Tm5qb+/X//xjVv3ly9e/fWN998U+UgDjRmJpNJrVu4lXslliYujhrQpZWyz+cp+3yBss/n6Xj6OWWfz9eFvMJy+3V1dlBefqEuf4+bV2DRgnXx2ncoQ2aTSWbzxQ/TxQ+zLvu6eHtR++qth20Cc3GfS744qKxz+ZLVKqskq1WyyqqL/5PVar3YVvT5pe1f7Ewps88PN/6qJi6OcnVykKuLg1ycHOTq7ChX56LPzebyr0RTE7MvBYUW5RdYlFdgUX5+ob6PP6nPvk2yuZHTv9fGK+dCvv4Q4S9nJwc5mE1VumxlbcwS0Sd91nWf53MLdDYnT2ezc3Um++J/c/J0NjtPZ3NydTY7T2eyc5VTRhArlpGZqyff3CIvN+eiD3cXebk5q5n77597uRdtu/Qux0Y/98ba5/ncAqVfDNkZWRf/m3mh6CMrV6ezcpV/2c/1spT1e88IhgXxxMRESVJwcLBNe2BgoCQpKSmpVBBPTExUYGCgHBxsXwjt2rUrcwYdQOXKuxLLhBEdyv1hWlBoUfb5fGWfy1fW+XzlnC/6b/a5PGWdz9fGnUfKPC4vv2i9usVilcWqov9arLJYL35YVPL1lTp3oUDLNv1atSddiezz+Zr3yS/lbnd2MheFdGdHuTg7yMXZQa7ODnJ1ctCexPQyw/2CdfH66WBaUbgusCivoFD5+RfDdkGh8kqCt+WKnn9+gUVLv/hVS78oeu5mk0kuzmY5OzrI2cksZycHOTs6yKX4cycHuTgWf27WNz8fK7POpV8cLHmjZRPrTWV+ahP+l3/1W7l9FlzBL8ayfFxBn7l5hbJKNm/Cir4s+sR68f8u32fV1kNl9rl4w0FlZF642Id+7+OSBusljdaSTeW/qVu84aBOZ+XKZCoaI5PJVPK52SSbr20+N0sfbvy13DeKzpcFwktV9H5sWTl9Ltv4q1ydyu+zIhX26VxBnSq/0PL6XLA2Xl//dPRi+M5Tbn7pSQFHB5O83FzUzN1ZLb2bqEPbZvJyd9YXP6SUGcibODsoIqi5zuTkKiOr6C7HWTl5KutV6ObqKE83ZzVzd5GXu7N2/3qq0jEqHo+yXk+mMl5YyzaV8/3cVDRB8Pu/v0sqvPzfq37/NyxV/G/J5ZJxN132iUmmy75WyXOqqE73Jk6qjvL6/PfaeK3ZdlgZWRd0Ptd2zE0mqZm7i3w8XRXk76Ee1/jK27Po6+aeLnr90z06nVU6dPt4ulSrxppmWBDPyiqaxnd3t52ud3NzkyRlZ2eXOiY7O7vU/sXHlLU/gMpV5Q6gxRwdzGrm7qJm7mX/IPvpYFqZsw1V+VNgUTD/Pag/+96OMn+Yenu46MVJfWTS76HQZCr6BWIyFf8S/P1zk0y6+D89/c+tZdbp5e6sR26J1IW8Ql3IK1BuXuHFzy9+nV9Yqi3nfL7Sz15Qbn7ZgTMv36Kjp3Lk5HgxLDs6yN3VSU4XA7KTk4OcHc0Xt5vldDFQOzma9cGa+HK/T38cdo1y8wuVl1+ovPyigF/8eXH72Zy8y7ZbygwwkpRzoaDccweqK+dCgT5YW/5zqG6fC2u4zvO5Bfp0c2KN9/nJ1wk12mf2+Xy9+Z89Ndpn1vl8vb6iFvr8tGb7zCuwyGwyKcjfoyQMF89iN7v4XzdXxzL/OuTbrEnZkw4jw0r9vCu0WJR1Lr9kZr14tv1syWx7nn47crbcvw7Wyhidq3iCoDqyz+frjZoe93P5ivv45xrtM7/AopbeTdQx0FvNPV3U3MO1JGh7uTvLwVz+pXlvHVz2ZFPMoNAarbG6DAvilS1NN5fxTa3omLL2r0xFa3Zqk68vJ5Xau8Y2RjcO9tCNg6+psf7uvj5Cbyz/2SbsuTg56O7rI6r9vb33hrL7vPeGCAW1bV6jdU6+sbP6RLauXp0vbVDa6fOl2n29m+jdPw+vVp+rth0ut8/xo8Or1ee9/7dBaWdK9+nj5aq4xwZdNrNW9s/eS5utVump179R+tkLZfY56+GB1arz6de/LbfPOY9eWzSLLF18c2X6ffbR5k1Z0Semi19Pm/2lTp0p3WeLZk30zjPDSo4rnv8rNaNpMtnMDErSpJe/KHuMmjXRP58ZJovFKqu16C9BVuvvbzCtVtl8fum2Z/+5RRllvFH09nDRC1Oiyvx+VfbHlL++t63cN7R/mdyv4oPL8cL728vt8/ny+qykzhf/VXafvt5N9Opjg6pTpm4c7CFPD1ctXLtfp06fVwvvJrorupMG92xb5v5XsriivNdR8Rhd/lca6dK/suiStt+/+L9/lT/p8P8m9ZVUeqb60k8vfRNS/Olf3i1/3P96X5RNjZfXV1zb5f+2/m/+Dp0po89mHi569p4+pdqvxMsffF9mn77eTfTiA9Vbz13Vca+Oq8kMhgXx4iuc5OTk2LQXz2yXdQUUd3d3HTlS+k/eOTk5Zc6UV4aTNVEWxujqRbRrprtGhZWaZY9o16za39tL+7z0BKaa6rOm6hw7ILjM2ZexA4Ltq8+BZfcZc22ICnLzq9VnzLUh5fZpKij/vILq9mnJK3/db0VuHlh2nzcPDNbZM+eq1We5YzQwWJlX0KdJvwcph4sNt5SzbOzWwaFyd6rezbnKmx28dXCoPF2qtzSloj69arjPq/k3LxW95mfeb/sm5mr6K+91VFtj1My1erGtoj49nKtX523l9Hnb4FD5NK3e0pTy+rS3cb9UvT1Zs3hteHJyssLCwkraDx8+bLP98mO2bdsmq9Vq847v8OHDZe4PwDhXcr3z6vZZk2+WarrO6iz1aYh91tTVHurjc68vfTa2MaoNjJH992nvDL184bBhw9StWzfNmTOnpO2xxx7T/v37tX79+lL7//DDD5owYYLmz59fcuWU4ssX3n///XrggQeq9PjMiKMsjJH9Y4zsH2Nk/xgj+8cY2b96OyMuSdOmTVNsbKy8vLw0ePBgbdq0SWvXri25rnhGRoaSk5PVvn17ubu7q3fv3urTp4+eeOIJTZ8+Xc2aNdPrr78uDw8P3XHHHUY+FQAAAKBKDA3iMTExysvL0/z587V8+XK1bdtWM2fO1OjRoyVJX3/9tWJjY7Vw4UL17Vt0gsIbb7yhV155RbNmzZLFYlHPnj312muvycvLy8inAgAAAFSJoUtTjMbSFJSFMbJ/jJH9Y4zsH2Nk/xgj+3e1S1Oqd6osAAAAgKtCEAcAAAAMQBAHAAAADEAQBwAAAAxAEAcAAAAMQBAHAAAADGDodcSNZjabGtXj4soxRvaPMbJ/jJH9Y4zsH2Nk/yoao8rGr1FfRxwAAAAwCktTAAAAAAMQxAEAAAADEMQBAAAAAxDEAQAAAAMQxAEAAAADEMQBAAAAAxDEAQAAAAMQxAEAAAADEMQBAAAAAxDE68iqVas0ZswYRUZGKjo6WitXrjS6JFyioKBAkZGRCgsLs/no3r270aVB0v79+xUREaHjx4/btH/33Xe65ZZb1LVrVw0dOlTz5883qMLGrbzxGT58eKnXVFhYmDIyMgyqtHGxWCz68MMPdcMNN6h79+667rrr9Pe//13Z2dkl++zZs0d/+tOf1L17dw0YMED/+Mc/lJ+fb2DVjcuVjNHdd99d5utoz549BlbeeFitVv373//WyJEjFRkZqRtvvFH//e9/bfa5mt9FjjVdMEpbs2aNpk+frokTJ2rAgAHauHGjZsyYIVdXV40aNcro8iApKSlJubm5mjlzpoKCgkrazWbeqxotISFB999/vwoKCmzaf/zxRz3wwAOKjo7Wo48+ql27dmnWrFmyWq2aNGmSQdU2PuWNT05OjlJSUvTkk0+qT58+Nts8PT3rssRG6/3339drr72mSZMmKSoqSklJSZo3b55+++03/etf/9Lhw4d19913q3v37nrttdeUkJCguLg4ZWdn6/nnnze6/EahsjGSpPj4eN11110aM2aMzbGhoaFGlNzovPPOO5o3b54efvhhdevWTd98842mT58uBwcHjR49+up/F1lR66677jrrY489ZtP26KOPWkeNGmVQRbjc559/bu3YsaP13LlzRpeCi/Lz862LFy+2du/e3dqnTx9rhw4drKmpqSXbJ06caL3ttttsjpk1a5a1V69e1tzc3Lout9GpbHx27dpl7dChg/W3334zsMrGy2KxWHv37m3961//atO+evVqa4cOHaz79u2z/vnPf7YOGjTI5vWyZMkSa6dOnazHjx+v65IbnSsZo+PHj1s7dOhg3bx5s0FVNm55eXnW3r17W1988UWb9gkTJljvuOMOq9V69b+LmO6rZSkpKUpOTtaIESNs2keOHKnExESlpKQYVBkutX//frVr105NmjQxuhRctGvXLr366qu69957NX36dJttubm52rlzZ5mvq8zMTP344491WWqjVNH4SEWvKVdXV5u/MKHu5OTk6MYbb9T1119v0x4SEiJJSk5O1pYtWzRkyBA5OzuXbB81apQKCwv13Xff1Wm9jdGVjFF8fLwkKSwsrM7rg+Tg4KBFixZpypQpNu1OTk7Kzc2tkd9FBPFalpiYKEkKDg62aQ8MDJRUtCQCxjtw4ICcnZ01adIkde/eXb1799bzzz9vs04PdSs0NFQbN27UQw89JAcHB5ttKSkpys/P53VloIrGRyp6TXl5eemJJ55Qr1691L17dz3++ONKS0szoNrGx93dXc8995x69uxp075x40ZJReOXmppa6jXUvHlzubu78xqqA5WNUfv27RUfHy9nZ2fNmzdPffv2VZcuXXTfffcxPnXEbDYrLCxMfn5+slqtOnXqlN59911t3bpV48aNq5HfRQTxWpaVlSWp6AV3KTc3N0ki6NmJ+Ph4JScna9CgQXr33Xf14IMPatWqVZo6daqsVqvR5TVKLVq0kI+PT5nbeF0Zr6LxkYpeU6dOndI111yjt99+W7Gxsfrhhx9011136cKFC3VYKYr9/PPPevfdd3XdddeVrNO//DUkFb2OeA0Z49IxCg0NVXx8vPLy8uTq6qo33nhDL7/8spKTkzV+/Hje1NaxDRs2qH///pozZ44GDRqkG2+8sUZ+F3GyZi2rLMRxMqB9iIuLk5eXV8mf/3r37i0fHx899dRT2rp1q/r3729whbgUryv799xzz8lqtapr166SpF69eik0NFR33nmnPv/8c91+++0GV9i47Nq1Sw888IDatGmjl156SXl5eRXuz2uo7l0+RpI0depUjRs3Tv369SvZr3v37oqOjtbixYv1+OOPG1VuoxMeHq7FixfrwIEDmjt3rqZMmaJHH320wmOu5HVEEK9lHh4ekorWgl2q+F1S8XYY6/KrOkjS4MGDJRXN7BHE7QuvK/sXGRlZqq1nz57y8PAoWfeKurFmzRo988wzCgoK0vvvvy9vb++S187lryGp6HXEa6hulTVGktShQ4dS+7Zt27Zkthx1p23btmrbtq169+4td3d3zZgxo2Tb1fwu4i1vLSteN5ScnGzTfvjwYZvtME56erqWL19e6sTZ4j+fF/9AhP1o166dHBwcSr2uir/mdWWsc+fO6dNPPy0VFCwWi/Lz83lN1aEPPvhATzzxhLp166YlS5aoZcuWkor+dO7n51fyu6hYenq6cnJyeA3VofLGyGq1auXKldq5c2epYy5cuMDrqA6cOXNGK1eu1IkTJ2zaw8PDJUlHjhy56t9FBPFaFhgYqDZt2mjdunU27Rs2bFBQUJACAgIMqgzFTCaTnn/+eS1evNimfc2aNXJwcCh1Ig2M5+Liol69emnDhg02y1TWr18vDw8Pde7c2cDq4OLioldeeUVvvPGGTfuXX36pCxculPkXKNS85cuX65VXXlF0dLTef//9UrNz/fv311dffWWzTGX9+vVycHBgjOpIRWNkMpn0r3/9S3/7299ksVhK2vfu3avk5GTGqA5YLBY988wz+uijj2zat2zZIknq0qXLVf8uYmlKHZg2bZpiY2Pl5eWlwYMHa9OmTVq7dq3i4uKMLg0qukrA+PHjtWjRIrm7u6tXr17atWuX3n77bY0fP77k7GfYl6lTp+qee+7R448/rptvvlk//fST/vWvf+nJJ5/kMpQGc3Bw0IMPPqhXXnlFL730koYOHaqDBw/q9ddf17Bhw9S3b1+jS2zw0tPT9fLLL6t169YaP3689u3bZ7O9Xbt2mjx5slavXq0pU6Zo4sSJOnTokP7xj3/o9ttvZ5KoDlzJGD300EN65JFHNH36dN1yyy06duyY5s6dq06dOummm24yqPLGo3nz5rrzzjv17rvvytXVVV26dNGuXbv0zjvv6LbbblNISMhV/y4yWbkkRJ1YtmyZ5s+fr9TUVLVt21ZTpkzR2LFjjS4LF+Xn5+vf//63Pv30Ux09elR+fn66/fbbNXnyZE5asgMrVqxQbGysNm/eLH9//5L2L774QvPmzVNSUpL8/Pw0fvx43XvvvQZW2jiVNz7Lly/XwoULlZycLC8vL91www16+OGH5erqamC1jcPKlStt1rBebtasWbrpppu0c+dOzZo1S/v375e3t7fGjh2rhx9+WE5OTnVYbeN0pWO0ceNGvf3220pISJCrq6uGDx+uJ554Qs2aNau7Yhux4nzwySef6NixY/L399ftt9+uSZMmleSDq/ldRBAHAAAADMBUHwAAAGAAgjgAAABgAII4AAAAYACCOAAAAGAAgjgAAABgAII4AAAAYABu6AMADcQzzzyj//znPxXuM2zYML311lt1VJGtoUOHqnXr1lq0aJEhjw8A9oYgDgANTGxsrLy9vcvc1qpVqzquBgBQHoI4ADQw1113ndq0aWN0GQCASrBGHAAAADAAQRwAGqGhQ4fq2Wef1fLlyzVs2DB169ZNf/zjH7V9+/ZS++7cuVN33323unfvru7du+uuu+7SDz/8UGq/n3/+Wffdd5969eqlvn37asqUKTpw4ECp/T7//HONGTNGnTt31siRI/Xhhx/WynMEAHtHEAeABiYzM1MZGRllfhQWFpbst3XrVr344osaOXKkHn30UWVkZGjy5Mn6/vvvS/bZtGmT/vSnPyk1NVVTp07V1KlTlZqaqrvvvlubNm0q2W/nzp0aP368EhISNHnyZE2dOlW//fab7rrrLh05cqRkvz179ujll1/WqFGjFBsbK2dnZ/31r3/Vxo0b6+abAwB2xGS1Wq1GFwEAuHpXctWUlStXqlOnTho6dKiOHj2qN998U9ddd50kKSMjQyNHjlRISIg++ugjFRQUaNiwYTKZTFq1apXc3d0lFQX966+/XlJRUHdyctJtt92m1NRU/fe//y05UTQpKUmjR4/WPffco6efflpDhw7VsWPH9OmnnyoiIkKSdPToUQ0bNkw33nijZs2aVVvfGgCwS5ysCQANzOzZs9WiRYsyt7Vr167k85CQkJIQLknNmzfXTTfdpMWLFys9PV1Hjx7V8ePHNX369JIQLkmenp6aMGGC5syZo//9739q166dfvnlF9177702V2sJDg7Wp59+anOllqCgoJIQLkmtW7dW8+bNderUqRp57gBQnxDEAaCB6dGjxxVdNaV9+/al2gIDA2W1WnX06NGSJSXBwcGl9gsJCZEkHTt2TA4ODiXHXi48PNzmax8fn1L7uLq6Kj8/v9J6AaChYY04ADRSTk5OpdqK15A7ODioopWLxducnJxksVgkSSaTqdLHNJv5tQMAxZgRB4BGKjk5uVTb4cOH5eDgoDZt2pTMUicmJpbaLykpSZLk7+8vPz+/cvubPXu2vLy8NGXKlJosHQAaBKYmAKCR2rNnj3bv3l3y9alTp/T555+rX79+8vLyUkREhHx9ffXhhx8qOzu7ZL/s7GwtXbpUvr6+6ty5s/z8/NSxY0etXr3aZr+UlBQtXLiQ9d8AUA5mxAGggdm4cWO5t7iXpJtuukmS5OzsrPvuu08TJ06Uq6urli5dKovFoqefflpS0bKT5557To8//rhuueUW3XrrrZKkTz75RCdPntS8efNKlprExsZq8uTJuuWWW3TbbbfJbDZr8eLF8vT01H333VfLzxgA6ieCOAA0MH//+98r3F4cxLt166YxY8borbfeUlZWlnr16qUnn3xSHTt2LNl31KhR8vLy0ltvvaU333xTjo6O6tq1q15++WX16tWrZL9+/fppwYIFmjdvnt588025uLiod+/eeuqpp+Tr61s7TxQA6jmuIw4AjdDQoUPVunVrLVq0yOhSAKDRYo04AAAAYACCOAAAAGAAgjgAAABgANaIAwAAAAZgRhwAAAAwAEEcAAAAMABBHAAAADAAQRwAAAAwAEEcAAAAMABBHAAAADDA/wcVvf+SsKdC2gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [SEP] And I want swift key to save the words I type 5 [SEP] youve been great to me\n"
     ]
    }
   ],
   "source": [
    "test_data_info = \"datasets/\" + app_name + \"/test/info.txt\"\n",
    "test_data_noninfo = \"datasets/\" + app_name + \"/test/non-info.txt\"\n",
    "# read data\n",
    "test_data1 = read_combine_data([test_data_info])\n",
    "test_data0 = read_combine_data([test_data_noninfo])\n",
    "\n",
    "testY = np.ones(test_data1.shape[0], dtype=int)\n",
    "testY = np.append(testY, np.zeros(test_data0.shape[0], dtype=int))\n",
    "testX = np.append(test_data1, test_data0, axis=0)\n",
    "\n",
    "print(test_data1[0], test_data0[613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1457410383.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prediction_labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = testX\n",
    "labels = torch.Tensor(testY).long()\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,007 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(\n",
    "    len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s, l_s = [],[]\n",
    "\n",
    "for b in predictions:\n",
    "    for t in b:\n",
    "        p_s.append(np.argmax(t))\n",
    "\n",
    "for b in true_labels:\n",
    "    for t in b:\n",
    "        l_s.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817083692838656 0.8739412057797707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "res_f1 = f1_score(p_s, l_s)\n",
    "res_acc = accuracy_score(p_s, l_s)\n",
    "\n",
    "print(res_f1, res_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178729c8f5e9eedf2bae7ea816478a89001acb4e6c66f13ce64ddbee9dd2f878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
