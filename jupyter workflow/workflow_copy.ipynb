{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only thing needed is swype to make it complete :) 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_reader import read_review_data, read_combine_data\n",
    "\n",
    "app_name = \"swiftkey\"\n",
    "training_data_info = \"datasets/\" + app_name + \"/trainL/info.txt\"\n",
    "training_data_noninfo = \"datasets/\" + app_name + \"/trainL/non-info.txt\"\n",
    "# read data\n",
    "training_data1 = read_review_data([training_data_info])\n",
    "training_data0 = read_review_data([training_data_noninfo])\n",
    "\n",
    "trainY = np.ones(training_data1.shape[0], dtype=int)\n",
    "trainY = np.append(trainY, np.zeros(training_data0.shape[0], dtype=int))\n",
    "trainX = np.append(training_data1, training_data0, axis=0)\n",
    "\n",
    "print(trainX[0], trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  The only thing needed is swype to make it complete :)\n",
      "Token IDs: [101, 1996, 2069, 2518, 2734, 2003, 25430, 18863, 2000, 2191, 2009, 3143, 1024, 1007, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in trainX:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        # This function also supports truncation and conversion\n",
    "        # to pytorch tensors, but we need to do padding, so we\n",
    "        # can't use these features :( .\n",
    "        #max_length = 128,          # Truncate all sentences.\n",
    "        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', trainX[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  43\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 43...\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "trainY = torch.Tensor(trainY).long()\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, trainY, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, trainY,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 2292, 1005, 1055, 2156, 2129, 2009, 3248, 2041, 2058, 2051,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0], dtype=torch.int32) tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1055863454.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1055863454.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_labels = torch.tensor(validation_labels)\n"
     ]
    }
   ],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "import torch\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "print(train_inputs[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(\n",
    "    validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=2,  # The number of output labels--2 for binary classification.\n",
    "    # You can increase this for multi-class tasks.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(\n",
    "    len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 30\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:09:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:06:58\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.74\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:07:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:18\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:06:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.74\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.75\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.77\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:49\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.75\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:18\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:19\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.75\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.77\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.74\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.75\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:07:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.74\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:07:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:07:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the\n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And I want swift key to save the words I type youve been great to me\n"
     ]
    }
   ],
   "source": [
    "test_data_info = \"datasets/\" + app_name + \"/test/info.txt\"\n",
    "test_data_noninfo = \"datasets/\" + app_name + \"/test/non-info.txt\"\n",
    "# read data\n",
    "test_data1 = read_review_data([test_data_info])\n",
    "test_data0 = read_review_data([test_data_noninfo])\n",
    "\n",
    "testY = np.ones(test_data1.shape[0], dtype=int)\n",
    "testY = np.append(testY, np.zeros(test_data0.shape[0], dtype=int))\n",
    "testX = np.append(test_data1, test_data0, axis=0)\n",
    "\n",
    "print(test_data1[0], test_data0[613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14412\\1457410383.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prediction_labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = testX\n",
    "labels = torch.Tensor(testY).long()\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,007 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(\n",
    "    len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s, l_s = [],[]\n",
    "\n",
    "for b in predictions:\n",
    "    for t in b:\n",
    "        p_s.append(np.argmax(t))\n",
    "\n",
    "for b in true_labels:\n",
    "    for t in b:\n",
    "        l_s.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407406 0.8535127055306427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "res_f1 = f1_score(p_s, l_s)\n",
    "res_acc = accuracy_score(p_s, l_s)\n",
    "\n",
    "print(res_f1, res_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "178729c8f5e9eedf2bae7ea816478a89001acb4e6c66f13ce64ddbee9dd2f878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
