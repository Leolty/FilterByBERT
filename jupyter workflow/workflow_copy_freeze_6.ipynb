{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [SEP] Can't change profile picture 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_reader import read_combine_data\n",
    "\n",
    "app_name = \"facebook\"\n",
    "training_data_info = \"datasets/\" + app_name + \"/trainL/info.txt\"\n",
    "training_data_noninfo = \"datasets/\" + app_name + \"/trainL/non-info.txt\"\n",
    "# read data\n",
    "training_data1 = read_combine_data([training_data_info])\n",
    "training_data0 = read_combine_data([training_data_noninfo])\n",
    "\n",
    "trainY = np.ones(training_data1.shape[0], dtype=int)\n",
    "trainY = np.append(trainY, np.zeros(training_data0.shape[0], dtype=int))\n",
    "trainX = np.append(training_data1, training_data0, axis=0)\n",
    "\n",
    "print(trainX[0], trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original:  1 [SEP] Can't change profile picture\n",
      "Token IDs: [101, 1015, 102, 2064, 1005, 1056, 2689, 6337, 3861, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in trainX:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "        # This function also supports truncation and conversion\n",
    "        # to pytorch tensors, but we need to do padding, so we\n",
    "        # can't use these features :( .\n",
    "        #max_length = 128,          # Truncate all sentences.\n",
    "        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', trainX[0])\n",
    "print('Token IDs:', input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  62\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 43...\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "trainY = torch.Tensor(trainY).long()\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, trainY, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, trainY,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1015,   102, 11896,  2000,  7170,  5167,  7919,   999,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], dtype=torch.int32) tensor(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16476\\1055863454.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16476\\1055863454.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_labels = torch.tensor(validation_labels)\n"
     ]
    }
   ],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "import torch\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "print(train_inputs[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(\n",
    "    validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=2,  # The number of output labels--2 for binary classification.\n",
    "    # You can increase this for multi-class tasks.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in list(model.named_parameters())[:-100]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 12\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 500, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:04:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.56\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 2 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:04:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.59\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 3 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:04:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 4 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:04:16\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 5 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:04:19\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "======== Epoch 6 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:04:21\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 7 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 8 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 9 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 10 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:04:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 11 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:04:17\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 12 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:04:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the\n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which\n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here:\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [SEP] i hate that i cant change my cover photo on the app 1 [SEP] getting annoyed with the new update\n"
     ]
    }
   ],
   "source": [
    "test_data_info = \"datasets/\" + app_name + \"/test/info.txt\"\n",
    "test_data_noninfo = \"datasets/\" + app_name + \"/test/non-info.txt\"\n",
    "# read data\n",
    "test_data1 = read_combine_data([test_data_info])\n",
    "test_data0 = read_combine_data([test_data_noninfo])\n",
    "\n",
    "testY = np.ones(test_data1.shape[0], dtype=int)\n",
    "testY = np.append(testY, np.zeros(test_data0.shape[0], dtype=int))\n",
    "testX = np.append(test_data1, test_data0, axis=0)\n",
    "\n",
    "print(test_data1[0], test_data0[613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16476\\1457410383.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prediction_labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = testX\n",
    "labels = torch.Tensor(testY).long()\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,016 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(\n",
    "    len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None,\n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s, l_s = [],[]\n",
    "\n",
    "for b in predictions:\n",
    "    for t in b:\n",
    "        p_s.append(np.argmax(t))\n",
    "\n",
    "for b in true_labels:\n",
    "    for t in b:\n",
    "        l_s.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732142857142856 0.8591269841269841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "res_f1 = f1_score(p_s, l_s)\n",
    "res_acc = accuracy_score(p_s, l_s)\n",
    "\n",
    "print(res_f1, res_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05fe49c8fe997e6843a0b35214a8e776cfd2b84c89e87e07e40c7afc5f3eae66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
